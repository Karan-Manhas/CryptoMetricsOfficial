print(dunn_cpu_kyber)
# Dunn’s Test for CPU Usage (ECDH)
dunn_cpu_ecdh <- dunnTest(cpu_percent ~ crypto_operation, data = ecdh_data_time_cpu, method = "bonferroni")
print(dunn_cpu_ecdh)
# Dunn’s Test for Heap Memory (Only for ECDH, since Kyber was not significant)
dunn_heap_ecdh <- dunnTest(heap_memory_kb ~ crypto_operation, data = ecdh_data_ram, method = "bonferroni")
print(dunn_heap_ecdh)
library(FSA)
# Dunn’s Test for Execution Time (Kyber)
dunn_time_kyber <- dunnTest(time_ns ~ crypto_operation, data = kyber_data_time_cpu, method = "bonferroni")
print(dunn_time_kyber)
# Dunn’s Test for Execution Time (ECDH)
dunn_time_ecdh <- dunnTest(time_ns ~ crypto_operation, data = ecdh_data_time_cpu, method = "bonferroni")
print(dunn_time_ecdh)
# Dunn’s Test for CPU Usage (Kyber)
dunn_cpu_kyber <- dunnTest(cpu_percent ~ crypto_operation, data = kyber_data_time_cpu, method = "bonferroni")
print(dunn_cpu_kyber)
# Dunn’s Test for CPU Usage (ECDH)
dunn_cpu_ecdh <- dunnTest(cpu_percent ~ crypto_operation, data = ecdh_data_time_cpu, method = "bonferroni")
print(dunn_cpu_ecdh)
# Dunn’s Test for Heap Memory (Only for ECDH, since Kyber was not significant)
dunn_heap_ecdh <- dunnTest(heap_memory_kb ~ crypto_operation, data = ecdh_data_ram, method = "bonferroni")
print(dunn_heap_ecdh)
library(ggplot2)
library(ggpubr)
# Create a data frame for the Dunn's Test results
dunn_results <- data.frame(
Algorithm = c("Kyber", "Kyber", "Kyber", "ECDH", "ECDH",
"Kyber", "Kyber", "Kyber", "ECDH", "ECDH",
"ECDH"),
Metric = c("Execution Time", "Execution Time", "Execution Time",
"Execution Time", "Execution Time",
"CPU Usage", "CPU Usage", "CPU Usage",
"CPU Usage", "CPU Usage",
"Heap Memory Usage"),
Comparison = c("Decapsulation - Encapsulation", "Decapsulation - Key Generation", "Encapsulation - Key Generation",
"Key Exchange - Key Generation", "Key Exchange - Key Generation",
"Decapsulation - Encapsulation", "Decapsulation - Key Generation", "Encapsulation - Key Generation",
"Key Exchange - Key Generation", "Key Exchange - Key Generation",
"Key Exchange - Key Generation"),
Z_Score = c(-39.48740, -24.79865, 14.68875,
37.98571, 37.98571,
-38.45284, -23.66199, 14.79085,
38.20373, 38.20373,
44.69902),
P_Value_Adjusted = c("< 0.00000000000000022", "< 0.00000000000000022", "< 0.000000000000002283",
"0", "0",
"< 0.00000000000000022", "< 0.00000000000000022", "< 0.000000000000000503",
"0", "0",
"0")
)
# Convert the table into a plot
table_plot <- ggtexttable(dunn_results, rows = NULL, theme = ttheme("minimal"))
# Display the table as a plot
ggarrange(table_plot, ncol = 1, nrow = 1)
## Kyber
spearman_kyber <- cor.test(kyber_data_time_cpu$time_ns, kyber_data_time_cpu$cpu_percent, method = "spearman")
print(spearman_kyber)
##ecdh
spearman_ecdh <- cor.test(ecdh_data_time_cpu$time_ns, ecdh_data_time_cpu$cpu_percent, method = "spearman")
print(spearman_ecdh)
#Speakrmans Rank Correlation Test for CPU Usage and exeuction time
## Kyber
spearman_kyber <- cor.test(kyber_data_time_cpu$time_ns, kyber_data_time_cpu$cpu_percent, method = "spearman")
print(spearman_kyber)
##ecdh
spearman_ecdh <- cor.test(ecdh_data_time_cpu$time_ns, ecdh_data_time_cpu$cpu_percent, method = "spearman")
print(spearman_ecdh)
# Load required libraries
library(ggplot2)
library(ggpubr)
# Create a data frame for Spearman correlation results
spearman_results <- data.frame(
Algorithm = c("Kyber", "ECDH"),
Metric_1 = c("Execution Time (ns)", "Execution Time (ns)"),
Metric_2 = c("CPU Usage (%)", "CPU Usage (%)"),
Correlation_Coefficient = c(0.9614664, 0.9867239),
P_Value = c("< 0.00000000000000022", "< 0.00000000000000022")
)
# Convert the table into a plot
table_plot <- ggtexttable(spearman_results, rows = NULL, theme = ttheme("minimal"))
# Display the table as a plot
ggarrange(table_plot, ncol = 1, nrow = 1)
library(ggplot2)
library(dplyr)
# Convert time from ns to ms for better visualization
kyber_data_time_cpu$time_ms <- kyber_data_time_cpu$time_ns / 1e6
ecdh_data_time_cpu$time_ms <- ecdh_data_time_cpu$time_ns / 1e6
# Combine datasets for plotting
scatter_time_cpu <- bind_rows(
kyber_data_time_cpu %>% select(time_ms, cpu_percent) %>% mutate(Algorithm = "Kyber"),
ecdh_data_time_cpu %>% select(time_ms, cpu_percent) %>% mutate(Algorithm = "ECDH")
)
# Execution Time vs CPU Usage (Scatter Plot)
ggplot(scatter_time_cpu, aes(x = cpu_percent, y = time_ms, color = Algorithm)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
labs(title = "Execution Time vs CPU Usage",
x = "CPU Usage (%)",
y = "Execution Time (ms)",
color = "Algorithm") +
theme_minimal()
# Combine datasets for Key Size vs Execution Time
scatter_key_time <- bind_rows(
kyber_data_time_cpu %>% select(key_size_bytes, time_ms) %>% mutate(Algorithm = "Kyber"),
ecdh_data_time_cpu %>% select(key_size_bytes, time_ms) %>% mutate(Algorithm = "ECDH")
)
# Key Size vs Execution Time (Scatter Plot)
ggplot(scatter_key_time, aes(x = key_size_bytes, y = time_ms, color = Algorithm)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
labs(title = "Key Size vs Execution Time",
x = "Key Size (Bytes)",
y = "Execution Time (ms)",
color = "Algorithm") +
theme_minimal()
# Execution Time vs CPU Usage (Scatter Plot)
ggplot(scatter_time_cpu, aes(x = cpu_percent, y = time_ms, color = Algorithm)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
labs(title = "Execution Time vs CPU Usage",
x = "CPU Usage (%)",
y = "Execution Time (ms)",
color = "Algorithm") +
theme_minimal()
library(ggcorrplot)
library(corrplot)
library(dplyr)
# Convert time from ns to ms for better readability
kyber_data_time_cpu$time_ms <- kyber_data_time_cpu$time_ns / 1e6
ecdh_data_time_cpu$time_ms <- ecdh_data_time_cpu$time_ns / 1e6
# Ensure there's a common key (iteration_no) for merging
kyber_corr_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ms, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
ecdh_corr_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ms, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
# Add Algorithm Labels
kyber_corr_data$Algorithm <- "Kyber"
ecdh_corr_data$Algorithm <- "ECDH"
# Combine Kyber and ECDH into one dataset
correlation_data <- bind_rows(kyber_corr_data, ecdh_corr_data)
# Remove NA values
correlation_data <- correlation_data %>% na.omit()
# Compute the Correlation Matrix using Spearman's Rank Correlation
correlation_matrix <- cor(correlation_data %>% select(time_ms, cpu_percent, heap_memory_kb, peak_rss_kb), method = "spearman")
# Visualize the Correlation Matrix
ggcorrplot(correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "Correlation Matrix (Execution Time, CPU Usage, Memory)")
library(ggcorrplot)
library(corrplot)
library(dplyr)
# Convert time from ns to ms for better readability
kyber_data_time_cpu$time_ms <- kyber_data_time_cpu$time_ns / 1e6
ecdh_data_time_cpu$time_ms <- ecdh_data_time_cpu$time_ns / 1e6
# Ensure there's a common key (iteration_no) for merging
kyber_corr_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ms, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
ecdh_corr_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ms, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
# Add Algorithm Labels
kyber_corr_data$Algorithm <- "Kyber"
ecdh_corr_data$Algorithm <- "ECDH"
# Combine Kyber and ECDH into one dataset
correlation_data <- bind_rows(kyber_corr_data, ecdh_corr_data)
# Remove NA values
correlation_data <- correlation_data %>% na.omit()
# Compute the Correlation Matrix including iteration_no using Spearman's Rank Correlation
correlation_matrix <- cor(correlation_data %>% select(iteration_no, time_ms, cpu_percent, heap_memory_kb, peak_rss_kb),
method = "spearman")
# Visualize the Correlation Matrix
ggcorrplot(correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "Correlation Matrix (Iteration, Execution Time, CPU Usage, Memory)")
# Load required libraries
library(ggcorrplot)
library(dplyr)
# Ensure there's a common key (iteration_no) for merging
kyber_corr_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
ecdh_corr_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
# Add Algorithm Labels
kyber_corr_data$Algorithm <- "Kyber"
ecdh_corr_data$Algorithm <- "ECDH"
# Combine Kyber and ECDH into one dataset
correlation_data <- bind_rows(kyber_corr_data, ecdh_corr_data)
# Remove NA values but ensure peak_rss_kb is not removed unnecessarily
correlation_data <- correlation_data %>% drop_na(time_ns, cpu_percent, heap_memory_kb, peak_rss_kb)
# Compute the Correlation Matrix including iteration_no and peak_rss_kb
correlation_matrix <- cor(correlation_data %>% select(iteration_no, time_ns, cpu_percent, heap_memory_kb, peak_rss_kb),
method = "spearman")
# Visualize the Correlation Matrix
ggcorrplot(correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "Correlation Matrix (Iteration, Execution Time, CPU Usage, Memory)",
colors = c("blue", "white", "red"))
# Load required libraries
library(ggcorrplot)
library(dplyr)
# Ensure there's a common key (iteration_no) for merging
kyber_corr_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
ecdh_corr_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
# Add Algorithm Labels
kyber_corr_data$Algorithm <- "Kyber"
ecdh_corr_data$Algorithm <- "ECDH"
# Combine Kyber and ECDH into one dataset
correlation_data <- bind_rows(kyber_corr_data, ecdh_corr_data)
# Remove NA values but ensure peak_rss_kb is not removed unnecessarily
correlation_data <- correlation_data %>% drop_na(time_ns, cpu_percent, heap_memory_kb, peak_rss_kb)
# Compute the Correlation Matrix including iteration_no and peak_rss_kb
correlation_matrix <- cor(correlation_data %>% select(iteration_no, time_ns, cpu_percent, heap_memory_kb, peak_rss_kb),
method = "spearman")
# Visualize the Correlation Matrix
ggcorrplot(correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "Correlation Matrix (Iteration, Execution Time, CPU Usage, Memory)",
colors = c("blue", "white", "red"))
# Load required libraries
library(ggcorrplot)
library(dplyr)
library(gridExtra)  # For arranging plots side by side
# Ensure there's a common key (iteration_no) for merging
kyber_corr_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
ecdh_corr_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
# Remove NA values for each dataset
kyber_corr_data <- kyber_corr_data %>% drop_na(time_ns, cpu_percent, heap_memory_kb, peak_rss_kb)
ecdh_corr_data <- ecdh_corr_data %>% drop_na(time_ns, cpu_percent, heap_memory_kb, peak_rss_kb)
# Compute Spearman Correlation Matrices for Kyber and ECDH
kyber_correlation_matrix <- cor(kyber_corr_data %>% select(iteration_no, time_ns, cpu_percent, heap_memory_kb, peak_rss_kb),
method = "spearman")
ecdh_correlation_matrix <- cor(ecdh_corr_data %>% select(iteration_no, time_ns, cpu_percent, heap_memory_kb, peak_rss_kb),
method = "spearman")
# Create Correlation Matrix Plots for Kyber and ECDH
kyber_plot <- ggcorrplot(kyber_correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "Kyber Correlation Matrix",
colors = c("blue", "white", "red"))
ecdh_plot <- ggcorrplot(ecdh_correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "ECDH Correlation Matrix",
colors = c("blue", "white", "red"))
# Display both correlation matrices side by side
grid.arrange(kyber_plot, ecdh_plot, ncol = 2)
str(kyber_data_time_cpu)
str(ecdh_data_time_cpu)
str(kyber_data_ram)
str(ecdh_data_ram)
length(unique(kyber_data_time_cpu$iteration_no)) == length(unique(kyber_data_ram$iteration_no))
length(unique(ecdh_data_time_cpu$iteration_no)) == length(unique(ecdh_data_ram$iteration_no))
# Load required libraries
library(ggcorrplot)
library(dplyr)
library(gridExtra)  # For arranging plots side by side
# Ensure 'iteration_no' exists in both datasets and merge correctly
kyber_corr_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
ecdh_corr_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb, peak_rss_kb), by = "iteration_no")
# Replace NA values in 'peak_rss_kb' with the median to avoid missing correlations
kyber_corr_data$peak_rss_kb[is.na(kyber_corr_data$peak_rss_kb)] <- median(kyber_corr_data$peak_rss_kb, na.rm = TRUE)
ecdh_corr_data$peak_rss_kb[is.na(ecdh_corr_data$peak_rss_kb)] <- median(ecdh_corr_data$peak_rss_kb, na.rm = TRUE)
# Remove remaining NA values
kyber_corr_data <- kyber_corr_data %>% drop_na(time_ns, cpu_percent, heap_memory_kb, peak_rss_kb)
ecdh_corr_data <- ecdh_corr_data %>% drop_na(time_ns, cpu_percent, heap_memory_kb, peak_rss_kb)
# Compute Spearman Correlation Matrices for Kyber and ECDH
kyber_correlation_matrix <- cor(kyber_corr_data %>% select(iteration_no, time_ns, cpu_percent, heap_memory_kb, peak_rss_kb),
method = "spearman")
ecdh_correlation_matrix <- cor(ecdh_corr_data %>% select(iteration_no, time_ns, cpu_percent, heap_memory_kb, peak_rss_kb),
method = "spearman")
# Create Correlation Matrix Plots for Kyber and ECDH
kyber_plot <- ggcorrplot(kyber_correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "Kyber Correlation Matrix",
colors = c("blue", "white", "red"))
ecdh_plot <- ggcorrplot(ecdh_correlation_matrix,
method = "square",
type = "lower",
lab = TRUE,
title = "ECDH Correlation Matrix",
colors = c("blue", "white", "red"))
# Display both correlation matrices side by side
grid.arrange(kyber_plot, ecdh_plot, ncol = 2)
summary(kyber_data_time_cpu)
summary(ecdh_data_time_cpu)
summary(kyber_data_ram)
summary(ecdh_data_ram)
# Load required libraries
library(ggplot2)
library(dplyr)
# Ensure merging of iteration_no with RAM data
kyber_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb), by = "iteration_no")
ecdh_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb), by = "iteration_no")
# Add Algorithm Labels
kyber_data$Algorithm <- "Kyber"
ecdh_data$Algorithm <- "ECDH"
# Combine the datasets
combined_data <- bind_rows(kyber_data, ecdh_data)
# Execution Time over Iterations
execution_time_plot <- ggplot(combined_data, aes(x = iteration_no, y = time_ns, color = Algorithm)) +
geom_line(alpha = 0.7) +
labs(title = "Execution Time Over Iterations", x = "Iteration Number", y = "Execution Time (ns)") +
theme_minimal()
# CPU Usage over Iterations
cpu_usage_plot <- ggplot(combined_data, aes(x = iteration_no, y = cpu_percent, color = Algorithm)) +
geom_line(alpha = 0.7) +
labs(title = "CPU Usage Over Iterations", x = "Iteration Number", y = "CPU Usage (%)") +
theme_minimal()
# Heap Memory over Iterations
heap_memory_plot <- ggplot(combined_data, aes(x = iteration_no, y = heap_memory_kb, color = Algorithm)) +
geom_line(alpha = 0.7) +
labs(title = "Heap Memory Over Iterations", x = "Iteration Number", y = "Heap Memory (KB)") +
theme_minimal()
# Display the plots
library(gridExtra)
grid.arrange(execution_time_plot, cpu_usage_plot, heap_memory_plot, ncol = 1)
# Load required libraries
library(ggplot2)
library(dplyr)
library(gridExtra)
# Merge Kyber and ECDH data
kyber_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(kyber_data_ram %>% select(iteration_no, heap_memory_kb), by = "iteration_no")
ecdh_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, cpu_percent) %>%
left_join(ecdh_data_ram %>% select(iteration_no, heap_memory_kb), by = "iteration_no")
# Add Algorithm Labels
kyber_data$Algorithm <- "Kyber"
ecdh_data$Algorithm <- "ECDH"
# Combine datasets
combined_data <- bind_rows(kyber_data, ecdh_data)
# Execution Time over Iterations with Smoother Trendline
execution_time_plot <- ggplot(combined_data, aes(x = iteration_no, y = time_ns, color = Algorithm)) +
geom_line(alpha = 0.5) +
geom_smooth(se = FALSE, method = "loess", span = 0.2) +  # Trendline
scale_y_continuous(limits = c(0, quantile(combined_data$time_ns, 0.99))) +  # Remove extreme outliers
scale_x_continuous(breaks = seq(0, 1000, 100)) +  # Better X-axis spacing
facet_wrap(~Algorithm) +  # Separate Kyber & ECDH
labs(title = "Execution Time Over Iterations", x = "Iteration Number", y = "Execution Time (ns)") +
theme_minimal()
# CPU Usage over Iterations with Scaling
cpu_usage_plot <- ggplot(combined_data, aes(x = iteration_no, y = cpu_percent, color = Algorithm)) +
geom_line(alpha = 0.5) +
geom_smooth(se = FALSE, method = "loess", span = 0.2) +
scale_y_continuous(limits = c(0, quantile(combined_data$cpu_percent, 0.99))) +
scale_x_continuous(breaks = seq(0, 1000, 100)) +
facet_wrap(~Algorithm) +
labs(title = "CPU Usage Over Iterations", x = "Iteration Number", y = "CPU Usage (%)") +
theme_minimal()
# Heap Memory over Iterations with Scaling
heap_memory_plot <- ggplot(combined_data, aes(x = iteration_no, y = heap_memory_kb, color = Algorithm)) +
geom_line(alpha = 0.5) +
geom_smooth(se = FALSE, method = "loess", span = 0.2) +
scale_y_continuous(limits = c(0, quantile(combined_data$heap_memory_kb, 0.99))) +
scale_x_continuous(breaks = seq(0, 1000, 100)) +
facet_wrap(~Algorithm) +
labs(title = "Heap Memory Over Iterations", x = "Iteration Number", y = "Heap Memory (KB)") +
theme_minimal()
# Display plots side by side
grid.arrange(execution_time_plot, cpu_usage_plot, heap_memory_plot, ncol = 1)
summary(kyber_data_time_cpu)
summary(ecdh_data_time_cpu)
summary(kyber_data_ram)
summary(ecdh_data_ram)
# Load required libraries
library(ggplot2)
library(dplyr)
library(gridExtra)
# Merge Kyber and ECDH data, including key_size_bytes
kyber_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, key_size_bytes) %>%
mutate(Algorithm = "Kyber")
ecdh_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, key_size_bytes) %>%
mutate(Algorithm = "ECDH")
# Combine both datasets
combined_data <- bind_rows(kyber_data, ecdh_data)
# ✅ Bar Chart: Average Execution Time per Key Size
bar_chart <- ggplot(combined_data, aes(x = factor(key_size_bytes), y = time_ns, fill = Algorithm)) +
stat_summary(fun = mean, geom = "bar", position = "dodge") +  # Bar chart using mean execution time
labs(title = "Bar Chart: Key Size vs. Execution Time", x = "Key Size (Bytes)", y = "Average Execution Time (ns)") +
theme_minimal()
# ✅ Scatter Plot: Key Size vs. Execution Time
scatter_plot <- ggplot(combined_data, aes(x = key_size_bytes, y = time_ns, color = Algorithm)) +
geom_point(alpha = 0.5) +  # Scatter plot with transparency
geom_smooth(method = "loess", se = FALSE) +  # Trendline to show pattern
labs(title = "Scatter Plot: Key Size vs. Execution Time", x = "Key Size (Bytes)", y = "Execution Time (ns)") +
theme_minimal()
# ✅ Display both plots side by side
grid.arrange(bar_chart, scatter_plot, ncol = 2)
# Load required libraries
library(ggplot2)
library(dplyr)
library(gridExtra)
# Merge Kyber and ECDH data, including key_size_bytes
kyber_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, key_size_bytes) %>%
mutate(Algorithm = "Kyber")
ecdh_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, key_size_bytes) %>%
mutate(Algorithm = "ECDH")
# Combine both datasets
combined_data <- bind_rows(kyber_data, ecdh_data)
# ✅ Bar Chart: Average Execution Time per Key Size
bar_chart <- ggplot(combined_data, aes(x = factor(key_size_bytes), y = time_ns, fill = Algorithm)) +
stat_summary(fun = mean, geom = "bar", position = "dodge") +  # Bar chart using mean execution time
labs(title = "Bar Chart: Key Size vs. Execution Time", x = "Key Size (Bytes)", y = "Average Execution Time (ns)") +
theme_minimal()
# ✅ Improved Scatter Plot: Key Size vs. Execution Time
scatter_plot <- ggplot(combined_data, aes(x = key_size_bytes, y = time_ns, color = Algorithm)) +
geom_jitter(alpha = 0.4, width = 10) +  # Add jitter to prevent overlapping points
geom_smooth(method = "loess", se = FALSE, span = 0.2) +  # Add trendline
scale_y_log10() +  # Use log scale for better visibility
labs(title = "Scatter Plot: Key Size vs. Execution Time", x = "Key Size (Bytes)", y = "Execution Time (ns, log scale)") +
theme_minimal()
# ✅ Display both plots side by side
grid.arrange(bar_chart, scatter_plot, ncol = 2)
str(kyber_data_time_cpu)
str(ecdh_data_time_cpu)
str(kyber_data_ram)
str(ecdh_data_ram)
library(ggplot2)
library(dplyr)
# Convert time from ns to ms
kyber_data_time_cpu$time_ms <- kyber_data_time_cpu$time_ns / 1e6
ecdh_data_time_cpu$time_ms <- ecdh_data_time_cpu$time_ns / 1e6
# Fix key sizes: Use shared_secret_key_size_bytes for Key Exchange
ecdh_data_time_cpu <- ecdh_data_time_cpu %>%
mutate(corrected_key_size = ifelse(crypto_operation == "Key Exchange",
shared_secret_key_size_bytes, key_size_bytes))
kyber_data_time_cpu <- kyber_data_time_cpu %>%
mutate(corrected_key_size = ifelse(crypto_operation %in% c("Encapsulation", "Decapsulation"),
shared_secret_key_size_bytes, key_size_bytes))
# Combine datasets with corrected key size
key_time_data <- bind_rows(
kyber_data_time_cpu %>% select(corrected_key_size, time_ms) %>% mutate(Algorithm = "Kyber"),
ecdh_data_time_cpu %>% select(corrected_key_size, time_ms) %>% mutate(Algorithm = "ECDH")
)
# Create the updated bar chart
ggplot(key_time_data, aes(x = factor(corrected_key_size), y = time_ms, fill = Algorithm)) +
stat_summary(fun = mean, geom = "bar", position = position_dodge(), width = 0.7) +
labs(title = "Average Execution Time by Key / Shared Secret Size",
x = "Key Size (Bytes) / Shared Secret Size (Bytes)",
y = "Execution Time (ms)",
fill = "Algorithm") +
theme_minimal()
library(ggplot2)
library(dplyr)
library(gridExtra)
ecdh_data_time_cpu <- ecdh_data_time_cpu %>%
mutate(corrected_key_size = ifelse(crypto_operation == "Key Exchange",
shared_secret_key_size_bytes, key_size_bytes))
kyber_data_time_cpu <- kyber_data_time_cpu %>%
mutate(corrected_key_size = ifelse(crypto_operation %in% c("Encapsulation", "Decapsulation"),
shared_secret_key_size_bytes, key_size_bytes))
kyber_data <- kyber_data_time_cpu %>%
select(iteration_no, time_ns, corrected_key_size) %>%
rename(key_size_bytes = corrected_key_size) %>%
mutate(Algorithm = "Kyber")
ecdh_data <- ecdh_data_time_cpu %>%
select(iteration_no, time_ns, corrected_key_size) %>%
rename(key_size_bytes = corrected_key_size) %>%
mutate(Algorithm = "ECDH")
combined_data <- bind_rows(kyber_data, ecdh_data)
bar_chart <- ggplot(combined_data, aes(x = factor(key_size_bytes), y = time_ns, fill = Algorithm)) +
stat_summary(fun = mean, geom = "bar", position = position_dodge(), width = 0.7) +  # Bar chart using mean execution time
labs(title = "Key Size vs. Execution Time", x = "Key Size (Bytes) / Shared Secret Size (Bytes)",
y = "Average Execution Time (ns)", fill = "Algorithm") +
theme_minimal()
scatter_plot <- ggplot(combined_data, aes(x = key_size_bytes, y = time_ns, color = Algorithm)) +
geom_jitter(alpha = 0.4, width = 10) +  # Add jitter to prevent overlapping points
geom_smooth(method = "loess", se = FALSE, span = 0.2) +  # Add trendline
scale_y_log10() +  # Use log scale for better visibility
labs(title = "Scatter Plot: Key Size vs. Execution Time", x = "Key Size (Bytes) / Shared Secret Size (Bytes)",
y = "Execution Time (ns, log scale)") +
theme_minimal()
grid.arrange(bar_chart, scatter_plot, ncol = 2)
